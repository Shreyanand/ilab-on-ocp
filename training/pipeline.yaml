# PIPELINE DEFINITION
# Name: launch-kubeflow-pytorchjob
# Description: An example to launch pytorch.
# Inputs:
#    delete_after_done: bool [Default: False]
#    job_timeout_minutes: int [Default: 600.0]
#    namespace: str [Default: 'mcliffor']
#    ttl_seconds_after_finished: int [Default: -1.0]
#    worker_replicas: int [Default: 1.0]
components:
  comp-create-worker-spec:
    executorLabel: exec-create-worker-spec
    inputDefinitions:
      parameters:
        worker_num:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      parameters:
        worker_spec:
          parameterType: STRUCT
  comp-name:
    executorLabel: exec-name
    inputDefinitions:
      parameters:
        active_deadline_seconds:
          isOptional: true
          parameterType: NUMBER_INTEGER
        backoff_limit:
          isOptional: true
          parameterType: NUMBER_INTEGER
        clean_pod_policy:
          defaultValue: Running
          isOptional: true
          parameterType: STRING
        delete_after_done:
          defaultValue: true
          isOptional: true
          parameterType: BOOLEAN
        job_timeout_minutes:
          defaultValue: 1440.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        master_spec:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        name:
          parameterType: STRING
        namespace:
          defaultValue: kubeflow
          isOptional: true
          parameterType: STRING
        ttl_seconds_after_finished:
          isOptional: true
          parameterType: NUMBER_INTEGER
        version:
          defaultValue: v1
          isOptional: true
          parameterType: STRING
        worker_spec:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
deploymentSpec:
  executors:
    exec-create-worker-spec:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - create_worker_spec
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.8.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef create_worker_spec(worker_num: int = 0) -> NamedTuple(\n    \"\
          CreatWorkerSpec\", [(\"worker_spec\", dict)]):\n    \"\"\"\n    Creates\
          \ pytorch-job worker spec\n    \"\"\"\n    from collections import namedtuple\n\
          \    worker = {}\n    if worker_num > 0:\n        worker = {\n         \
          \   \"replicas\": worker_num,\n            \"restartPolicy\": \"OnFailure\"\
          ,\n            \"template\": {\n                \"metadata\": {\n      \
          \              \"annotations\": {\n                        \"sidecar.istio.io/inject\"\
          : \"false\"\n                    }\n                },\n               \
          \ \"spec\": {\n                    \"containers\": [\n                 \
          \       {   \"command\": [\n                            '/bin/bash',\n \
          \                           '-c',\n                            '--'\n  \
          \                          ],\n                            \"args\": [\n\
          \                            \"python3.11 -u run.py\"\n                \
          \            ],\n                            \"image\": \"quay.io/michaelclifford/test-train:0.0.11\"\
          ,\n                            \"name\": \"pytorch\",\n                \
          \            \"resources\": {\n                                \"requests\"\
          : {\n                                    \"memory\": \"8Gi\",\n        \
          \                            \"cpu\": \"2000m\",\n                     \
          \               # Uncomment for GPU\n                                  \
          \  \"nvidia.com/gpu\": 1,\n                                },\n        \
          \                        \"limits\": {\n                               \
          \     \"memory\": \"8Gi\",\n                                    \"cpu\"\
          : \"2000m\",\n                                    # Uncomment for GPU\n\
          \                                    \"nvidia.com/gpu\": 1,\n          \
          \                      },\n                            },\n            \
          \            }\n                    ]\n                },\n            },\n\
          \        }\n\n    worker_spec_output = namedtuple(\n        \"MyWorkerOutput\"\
          , [\"worker_spec\"]\n    )\n    return worker_spec_output(worker)\n\n"
        image: python:slim
    exec-name:
      container:
        args:
        - --name
        - '{{$.inputs.parameters[''name'']}}'
        - --namespace
        - '{{$.inputs.parameters[''namespace'']}}'
        - --version
        - '{{$.inputs.parameters[''version'']}}'
        - --masterSpec
        - '{{$.inputs.parameters[''master_spec'']}}'
        - --workerSpec
        - '{{$.inputs.parameters[''worker_spec'']}}'
        - --jobTimeoutMinutes
        - '{{$.inputs.parameters[''job_timeout_minutes'']}}'
        - --deleteAfterDone
        - '{{$.inputs.parameters[''delete_after_done'']}}'
        - --cleanPodPolicy
        - '{{$.inputs.parameters[''clean_pod_policy'']}}'
        - --activeDeadlineSeconds
        - '{{$.inputs.parameters[''active_deadline_seconds'']}}'
        - --backoffLimit
        - '{{$.inputs.parameters[''backoff_limit'']}}'
        - --ttlSecondsAfterFinished
        - '{{$.inputs.parameters[''ttl_seconds_after_finished'']}}'
        command:
        - python
        - /ml/launch_pytorchjob.py
        image: cascribner/kubeflow-pytorchjob-launcher:v1
pipelineInfo:
  description: An example to launch pytorch.
  name: launch-kubeflow-pytorchjob
root:
  dag:
    tasks:
      create-worker-spec:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-create-worker-spec
        inputs:
          parameters:
            worker_num:
              componentInputParameter: worker_replicas
        taskInfo:
          name: create-worker-spec
      name:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-name
        dependentTasks:
        - create-worker-spec
        inputs:
          parameters:
            active_deadline_seconds:
              runtimeValue:
                constant: 100.0
            backoff_limit:
              runtimeValue:
                constant: 1.0
            delete_after_done:
              componentInputParameter: delete_after_done
            job_timeout_minutes:
              componentInputParameter: job_timeout_minutes
            master_spec:
              runtimeValue:
                constant:
                  replicas: 1.0
                  restartPolicy: OnFailure
                  template:
                    metadata:
                      annotations:
                        sidecar.istio.io/inject: 'false'
                    spec:
                      containers:
                      - args:
                        - python3.11 -u run.py
                        command:
                        - /bin/bash
                        - -c
                        - --
                        image: quay.io/michaelclifford/test-train:0.0.11
                        name: pytorch
                        resources:
                          limits:
                            cpu: 2000m
                            memory: 8Gi
                            nvidia.com/gpu: 1.0
                          requests:
                            cpu: 2000m
                            memory: 8Gi
                            nvidia.com/gpu: 1.0
            name:
              runtimeValue:
                constant: pytorch-job
            namespace:
              componentInputParameter: namespace
            ttl_seconds_after_finished:
              componentInputParameter: ttl_seconds_after_finished
            worker_spec:
              taskOutputParameter:
                outputParameterKey: worker_spec
                producerTask: create-worker-spec
        taskInfo:
          name: name
  inputDefinitions:
    parameters:
      delete_after_done:
        defaultValue: false
        isOptional: true
        parameterType: BOOLEAN
      job_timeout_minutes:
        defaultValue: 600.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      namespace:
        defaultValue: mcliffor
        isOptional: true
        parameterType: STRING
      ttl_seconds_after_finished:
        defaultValue: -1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      worker_replicas:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.8.0
