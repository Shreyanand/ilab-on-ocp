{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade kubeflow-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func():\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import DistributedSampler\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "\n",
    "    # [1] Setup PyTorch DDP. WORLD_SIZE and RANK environments will be set by Training Operator.\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    Distributor = torch.nn.parallel.DistributedDataParallel\n",
    "\n",
    "\n",
    "    # [2] Create PyTorch CNN Model.\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = torch.nn.Conv2d(1, 20, 5, 1)\n",
    "            self.conv2 = torch.nn.Conv2d(20, 50, 5, 1)\n",
    "            self.fc1 = torch.nn.Linear(4 * 4 * 50, 500)\n",
    "            self.fc2 = torch.nn.Linear(500, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.max_pool2d(x, 2, 2)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool2d(x, 2, 2)\n",
    "            x = x.view(-1, 4 * 4 * 50)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "    # [3] Attach model to GPU and distributor.\n",
    "    device = \"cuda\"\n",
    "    model = Net().to(device)\n",
    "    model = Distributor(model)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "    # [4] Setup FashionMNIST dataloader and distribute data across PyTorchJob workers.\n",
    "    dataset = datasets.FashionMNIST(\n",
    "        \"./data\",\n",
    "        download=True,\n",
    "        train=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor()]),\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=128,\n",
    "        sampler=DistributedSampler(dataset),\n",
    "    )\n",
    "\n",
    "    # [5] Start model Training.\n",
    "    for epoch in range(3):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Attach Tensors to the device.\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(\n",
    "                    \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss={:.4f}\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * len(data),\n",
    "                        len(train_loader.dataset),\n",
    "                        100.0 * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 (DONE)\n",
    "# Get a very simple pytorch job definition without adding advanced parameters\n",
    "# use training_client.create_job function \n",
    "# https://github.com/kubeflow/training-operator/blob/master/sdk/python/kubeflow/training/api/training_client.py\n",
    "# this may not run but we get something\n",
    "\n",
    "from kubeflow.training.utils import utils\n",
    "import logging\n",
    "from kubeflow.training import models\n",
    "from kubeflow.training.constants import constants\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "status_logger = utils.StatusLogger(\n",
    "    header=\"{:<30.30} {:<20.20} {}\".format(\"NAME\", \"STATE\", \"TIME\"),\n",
    "    column_format=\"{:<30.30} {:<20.20} {}\",\n",
    ")\n",
    "\n",
    "base_image = \"quay.io/shanand/test-train:v0.1\"\n",
    "namespace = \"shreyanand\"\n",
    "num_workers = 1\n",
    "container_name = \"PYTORCHJOB_CONTAINER\"\n",
    "name = \"test-kfp\"\n",
    "\n",
    "container_spec = utils.get_container_spec(\n",
    "    name=\"PYTORCHJOB_CONTAINER\",\n",
    "    base_image=base_image,\n",
    "    train_func=train_func\n",
    ")\n",
    "\n",
    "# Get Pod template spec using the above container.\n",
    "pod_template_spec = utils.get_pod_template_spec(\n",
    "    containers=[container_spec],\n",
    ")\n",
    "\n",
    "job = utils.get_pytorchjob_template(\n",
    "    name=name,\n",
    "    namespace=namespace,\n",
    "    worker_pod_template_spec=pod_template_spec,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kubeflow.training.models.kubeflow_org_v1_py_torch_job.KubeflowOrgV1PyTorchJob"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2a (To do)\n",
    "# Run the job using a launcher client \n",
    "# that waits for the succeded or failed\n",
    "# taken from https://github.com/kubeflow/pipelines/blob/master/components/kubeflow/pytorch-launcher/src/launch_pytorchjob.py\n",
    "\n",
    "from kubernetes import client as k8s_client\n",
    "from kubernetes import config\n",
    "import launch_crd\n",
    "\n",
    "serialized_job = k8s_client.ApiClient().sanitize_for_serialization(job)\n",
    "\n",
    "logging.info('Creating launcher client.')\n",
    "\n",
    "config.load_incluster_config()\n",
    "api_client = k8s_client.ApiClient()\n",
    "launcher_client = launch_crd.K8sCR(\n",
    "    group=args.jobGroup,\n",
    "    plural=args.jobPlural,\n",
    "    version=args.version,\n",
    "    client=api_client\n",
    ")\n",
    "\n",
    "logging.info('Submitting CR.')\n",
    "create_response = launcher_client.create(serialized_job)\n",
    "\n",
    "expected_conditions = [\"Succeeded\", \"Failed\"]\n",
    "logging.info(\n",
    "    f'Monitoring job until status is any of {expected_conditions}.'\n",
    ")\n",
    "launcher_client.wait_for_condition(\n",
    "    args.namespace, args.name, expected_conditions,\n",
    "    timeout=datetime.timedelta(minutes=args.jobTimeoutMinutes))\n",
    "if args.deleteAfterDone:\n",
    "    logging.info('Deleting job.')\n",
    "    launcher_client.delete(args.name, args.namespace)\n",
    "\n",
    "\n",
    "# STEP 2b (To do)\n",
    "# However this is probably outdated code\n",
    "# We could actually rewrite this using training_client.create_job()\n",
    "# and training_client.is_job_succeded(), training_client.is_job_failed()\n",
    "# https://github.com/kubeflow/training-operator/blob/master/sdk/python/kubeflow/training/api/training_client.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 (to do) Can also do this after step 4\n",
    "\n",
    "# Run the above as a dsl component \n",
    "# basic image + kubeflow.training installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "\n",
    "# Completely define the Pytorch job \n",
    "# If you complete step 2b, you can directly use training_client.train() for this\n",
    "# If there are issues, adapt training_client.train() code for this use case\n",
    "# Once you have a well defined Pytorch job; run the job using the final output of step 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
